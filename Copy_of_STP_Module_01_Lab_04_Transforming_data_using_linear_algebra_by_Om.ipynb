{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU9LZjQxiQT2"
      },
      "source": [
        "# Transforming data using linear algebra\n",
        "\n",
        "Module 1, Lab 4\n",
        "\n",
        "Matrix transformations are at the heart of many machine learning algorithms. In this lab, we'll visualize the effect of some simple transformations on a unit square and then visualize it using the MNIST dataset. We also see what data normalization means and how it can help in improving the accuracy of machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KBe4ZA32UTbv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "b6fa68c2-1f1c-46d6-d0ce-bccb04d6b439"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1459968628.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_tf_keras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_tf_keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/_tf_keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/_tf_keras/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/activations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/activations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0melu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexponential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/activations/activations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresult_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0many_symbolic_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/common/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresult_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutocastScope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mKerasVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_autocast_scope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/common/dtypes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstandardize_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mBOOL_TYPES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"bool\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateless_scope\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_stateless_scope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateless_scope\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0min_stateless_scope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaming\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauto_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_dataset_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio_dataset_from_directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msplit_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dataset_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage_dataset_from_directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_to_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/audio_dataset_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_io\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/dataset_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/tree/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0massert_same_paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0massert_same_structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflatten_with_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_nested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/tree/tree_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moptree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptree_impl\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtree_impl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mdmtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdmtree_impl\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtree_impl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/tree/optree_impl.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Register backend-specific node classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tensorflow\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_structures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mListWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_structures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_DictWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_ctx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_status_ctx\u001b[0m \u001b[0;31m# line: 34\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_convert\u001b[0m \u001b[0;31m# line: 493\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/core/ag_ctx.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mag_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_managers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_dependency_on_returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malias_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_list\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdynamic_list_append\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/utils/context_managers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_array_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_flow_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_control_flow_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_data_flow_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/gen_control_flow_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m \u001b[0mNoOp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw_ops.NoOp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_raw_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0m_dispatcher_for_no_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mno_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_type_based_dispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mto_raw_op\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m   5999\u001b[0m   f = types.FunctionType(f.__code__, f.__globals__, f.__name__, f.__defaults__,\n\u001b[1;32m   6000\u001b[0m                          f.__closure__)\n\u001b[0;32m-> 6001\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mkwarg_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/tf_export.py\u001b[0m in \u001b[0;36mkwarg_only\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator_argspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_argspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/tf_decorator.py\u001b[0m in \u001b[0;36mmake_decorator\u001b[0;34m(target, decorator_func, decorator_name, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    157\u001b[0m   \u001b[0mdecorator_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__original_wrapped__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdecorator_argspec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     decorator_func.__signature__ = fullargspec_to_signature(\n\u001b[0m\u001b[1;32m    160\u001b[0m         decorator_argspec)\n\u001b[1;32m    161\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/tf_decorator.py\u001b[0m in \u001b[0;36mfullargspec_to_signature\u001b[0;34m(fullargspec)\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfullargspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     parameters.append(\n\u001b[0;32m---> 86\u001b[0;31m         inspect.Parameter(\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOSITIONAL_OR_KEYWORD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2741\u001b[0m     \u001b[0mempty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2743\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2744\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2745\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ParameterKind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7mqG-dafVpya"
      },
      "outputs": [],
      "source": [
        "# You don't need to understand these functions\n",
        "\n",
        "\n",
        "def plotGrid(transform, unit, linestyle=\":\", fig=None, ax=None):\n",
        "    lim1 = -100\n",
        "    lim2 = 100\n",
        "\n",
        "    def mat2xy(start, end):\n",
        "        if len(start.shape) == 1:\n",
        "            start = np.expand_dims(start, 0)\n",
        "            end = np.expand_dims(end, 0)\n",
        "        nan = np.ones(len(start)) * np.nan\n",
        "        x = np.stack((start[:, 0], end[:, 0], nan)).T.reshape(-1)\n",
        "        y = np.stack((start[:, 1], end[:, 1], nan)).T.reshape(-1)\n",
        "        return x, y\n",
        "\n",
        "    def parallellines(axis, addend, lines, unit):\n",
        "        addend = np.repeat(np.expand_dims(addend, 0), lines * 2, 0)\n",
        "        unit = np.expand_dims(np.arange(-lines, lines) * unit, 1)\n",
        "        unit = unit - lines\n",
        "        addend = addend * unit\n",
        "        lines = np.expand_dims(axis, 0) + addend\n",
        "        return np.concatenate((lines, lines * -1))\n",
        "\n",
        "    if fig is None:\n",
        "        fig, ax = plt.subplots(figsize=(5, 5))\n",
        "    transform = transform.astype(float)\n",
        "    xaxis = transform[0]\n",
        "    yaxis = transform[1]\n",
        "\n",
        "    # plot lines parallel to the x axis\n",
        "    lines1 = parallellines(xaxis * lim1, yaxis, 100, unit)\n",
        "    lines2 = parallellines(xaxis * lim2, yaxis, 100, unit)\n",
        "    x, y = mat2xy(lines1, lines2)\n",
        "    plt.plot(x, y, linestyle + \"k\", linewidth=0.5)\n",
        "    # plot x axis\n",
        "    x, y = mat2xy(xaxis * lim1, xaxis * lim2)\n",
        "    plt.plot(x, y, linestyle, color=\"#440077\")\n",
        "\n",
        "    # plot  lines parallel to the y axis\n",
        "    lines1 = parallellines(yaxis * lim1, xaxis, 100, unit)\n",
        "    lines2 = parallellines(yaxis * lim2, xaxis, 100, unit)\n",
        "    x, y = mat2xy(lines1, lines2)\n",
        "    plt.plot(x, y, linestyle + \"k\", linewidth=0.5)\n",
        "    # plot y axis\n",
        "    x, y = mat2xy(yaxis * lim1, yaxis * lim2)\n",
        "    plt.plot(x, y, linestyle, color=\"#aa5500\")\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "def plotData(X, y, xlabel=\"hole\", ylabel=\"bound\", fig=None, ax=None):\n",
        "    if fig is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    for ii in range(nclasses):\n",
        "        plt.scatter(X[y == ii, 0], X[y == ii, 1])\n",
        "    plt.legend([str(i) for i in range(nclasses)])\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    lim2 = X.max()\n",
        "    lim1 = X.min()\n",
        "    return fig, ax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d5dmEXxaktp"
      },
      "source": [
        "## Matrix transformations on data\n",
        "\n",
        "Note: This lab involves a lot of matrix operations. If you are not familiar with them, please go through the resources given in class before proceeding. You can also review Khan Academy's excellent linear algebra [resources](https://www.khanacademy.org/math/linear-algebra/matrix-transformations).\n",
        "\n",
        "A 2D coordinate system is defined by its basis vectors, i and j. Any point in this 2D space can be represented as a linear combination of these basis vectors. For example, the point (a,b) can be represented as:\n",
        "\n",
        "$$\\begin{equation}\n",
        "\\left\\{  \\begin{aligned}a \\\\ b \\end{aligned} \\right\\} = a\\left\\{  \\begin{aligned}1 \\\\ 0 \\end{aligned} \\right\\} + b\\left\\{  \\begin{aligned}0 \\\\ 1 \\end{aligned} \\right\\} = a\\hat{i} + b\\hat{j}\n",
        "\\end{equation}$$\n",
        "\n",
        "A matrix can be used to perform a linear transformation on the basis vectors. The new basis vectors $\\hat{i}$ and $\\hat{j}$ are given by the product of the matrix and the basis vectors of the standard coordinate system.\n",
        "\n",
        "In the standard coordinate system (Let us call it T0), the basis vectors are\n",
        "\n",
        "$$\\begin{equation}\n",
        "i = \\left\\{  \\begin{aligned}1 \\\\ 0 \\end{aligned} \\right\\}\n",
        "\\end{equation}$$\n",
        "and\n",
        "$$\\begin{equation} j = \\left\\{ \\begin{aligned} 0 \\\\ 1\\end{aligned} \\right\\} \\end{equation}$$\n",
        "\n",
        "We can use any two vectors as basis vectors for a new coordinate system as long as they are not colinear. For example, let us call this new coordinate system T1:\n",
        "\n",
        "$$\\begin{equation}\n",
        "i = \\left\\{  \\begin{aligned}1 \\\\ -1 \\end{aligned} \\right\\}\n",
        "\\end{equation}$$\n",
        "and\n",
        "$$\\begin{equation} j = \\left\\{ \\begin{aligned} 0 \\\\ 2 \\end{aligned} \\right\\} \\end{equation}$$\n",
        "\n",
        "Suppose we have a point [a,b] in the T1 coordinate system. Its representation in the standard system T0 can be obtained by the following matrix multiplication:\n",
        "\n",
        "$$ \\begin{equation}\n",
        "\\left\\{  \\begin{aligned}a' \\\\ b' \\end{aligned} \\right\\} =\n",
        "\\left\\{  \\begin{aligned}&1 & 0 \\\\ -&1 & 2 \\end{aligned} \\right\\}\n",
        "\\left\\{  \\begin{aligned}a \\\\ b \\end{aligned} \\right\\}\n",
        "\\end{equation}$$\n",
        "where the columns of the matrix are the basis vectors of T1.\n",
        "\n",
        "\n",
        "Let us see this in action:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8SCFKqfbM-l"
      },
      "outputs": [],
      "source": [
        "T0 = np.array([[1, 0], [0, 1]])\n",
        "T1 = np.array([[1, 0], [-1, 2]])\n",
        "\n",
        "data1 = np.array([5, 4])  # the data in T1 coordinate system\n",
        "data0 = np.matmul(T1, data1)  # the data in T0 coordinate system\n",
        "\n",
        "print(\"Data in T0 = \", data0)\n",
        "print(\"Data in T1 = \", data1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIfEWZ1RQeve"
      },
      "source": [
        "We can visualize this below. T0 is shown with dotted lines and T1 is shown with solid lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSuTaeSDQoYK"
      },
      "outputs": [],
      "source": [
        "fig, ax = plotGrid(T1.T, 1, \"-\")\n",
        "plotGrid(T0.T, 1, fig=fig, ax=ax)\n",
        "\n",
        "plt.scatter(data0[0], data0[1])\n",
        "ax.set_xlim(-10, 10)\n",
        "ax.set_ylim(-10, 10)\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What Are Basis Vectors?\n",
        "\n",
        "Think of basis vectors as the **\"rulers\"** of your coordinate system. Just like measuring distance in meters vs feet changes the numbers but not the actual distance, different basis vectors represent the same point differently.\n",
        "\n",
        "**Standard Coordinate System (T0):**\n",
        "- Basis vectors: **î** = [1, 0] and **ĵ** = [0, 1]\n",
        "- Point [5, 3] means: \"5 steps along x-axis, 3 steps along y-axis\"\n",
        "\n",
        "**Transformed Coordinate System (T1):**\n",
        "- Basis vectors: **î** = [1, -1] and **ĵ** = [0, 2]\n",
        "- Point [5, 4] in T1 = Point [5, 3] in T0 (same location, different description!)\n",
        "\n",
        "---\n",
        "\n",
        "### Matrix Transformation Formula\n",
        "\n",
        "Converting from T1 to T0:\n",
        "\n",
        "$$\\begin{bmatrix} x_{T0} \\\\ y_{T0} \\end{bmatrix} = \\begin{bmatrix} \\text{î}_x & \\text{ĵ}_x \\\\ \\text{î}_y & \\text{ĵ}_y \\end{bmatrix} \\begin{bmatrix} x_{T1} \\\\ y_{T1} \\end{bmatrix}$$\n",
        "\n",
        "Where columns of the matrix are the basis vectors of T1.\n",
        "\n",
        "**Example:**\n",
        "$$\\begin{bmatrix} 5 \\\\ 3 \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ -1 & 2 \\end{bmatrix} \\begin{bmatrix} 5 \\\\ 4 \\end{bmatrix}$$\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "gAPIf7aY81y4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUb3oYWIgdya"
      },
      "source": [
        "Look at the coordinates of the blue dot. In T0 (dotted lines), the position is [5,3] where it is [5,4] in T1. Feel free to experiment with different data points and coordinate systems.\n",
        "\n",
        "Remember that we can achieve the same thing by post-multiplying the transpose of the transformation matrix to the data. This will come in handy when transforming multiple data points at once:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SD4pqOMndf-4"
      },
      "outputs": [],
      "source": [
        "data0_a = np.matmul(T1, data1)\n",
        "data0_b = np.matmul(data1, T1.T)\n",
        "print(data0_a)\n",
        "print(data0_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-Kui3dSESPm"
      },
      "source": [
        "Why is transforming data useful? Data transformations cause the distance between data points to change. This will affect distance-based algorithms such as nearest neighbour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE0NbpYIC9ou"
      },
      "outputs": [],
      "source": [
        "# let us define 3 points in T1\n",
        "A1 = np.array([3, 3])\n",
        "B1 = np.array([2, -5])\n",
        "C1 = np.array([1, -1])\n",
        "\n",
        "# the corresponding points in T0:\n",
        "A0 = np.matmul(T1, A1)\n",
        "B0 = np.matmul(T1, B1)\n",
        "C0 = np.matmul(T1, C1)\n",
        "\n",
        "\n",
        "def dist(a, b):\n",
        "    # function to calculate Euclidean distance between two points\n",
        "    diff = a - b\n",
        "    sq = diff * diff\n",
        "    return np.sqrt(sq.sum())\n",
        "\n",
        "\n",
        "# distance between the points in T1\n",
        "print(\"Distance between A and B in T1 = \", dist(A1, B1))\n",
        "print(\"Distance between B and C in T1 = \", dist(B1, C1))\n",
        "print(\"Distance between A and C in T1 = \", dist(A1, C1))\n",
        "\n",
        "print(\"\")\n",
        "# distnace between the points in T0\n",
        "print(\"Distance between A and B in T0 = \", dist(A0, B0))\n",
        "print(\"Distance between B and C in T0 = \", dist(B0, C0))\n",
        "print(\"Distance between A and C in T0 = \", dist(A0, C0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE95JMniUtDm"
      },
      "source": [
        "We see that in T1, B and C are the closest whereas in T0, A and C are the closest. These kinds of changes will affect the predictions returned by the nearest neighbour algorithm."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize how transformation changes point relationships\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Plot in T1 (original space)\n",
        "ax1.scatter([A1[0], B1[0], C1[0]], [A1[1], B1[1], C1[1]],\n",
        "            s=200, c=['red', 'blue', 'green'], alpha=0.7)\n",
        "ax1.plot([A1[0], B1[0]], [A1[1], B1[1]], 'k--', linewidth=2, label='A-B')\n",
        "ax1.plot([B1[0], C1[0]], [B1[1], C1[1]], 'k:', linewidth=2, label='B-C')\n",
        "ax1.plot([A1[0], C1[0]], [A1[1], C1[1]], 'k-.', linewidth=2, label='A-C')\n",
        "ax1.scatter([A1[0], B1[0], C1[0]], [A1[1], B1[1], C1[1]],\n",
        "            s=200, c=['red', 'blue', 'green'], alpha=0.7)\n",
        "ax1.text(A1[0]+0.3, A1[1]+0.3, 'A', fontsize=14, fontweight='bold')\n",
        "ax1.text(B1[0]+0.3, B1[1]+0.3, 'B', fontsize=14, fontweight='bold')\n",
        "ax1.text(C1[0]+0.3, C1[1]+0.3, 'C', fontsize=14, fontweight='bold')\n",
        "ax1.set_title('Original Space (T1)\\nB-C are closest', fontsize=12, fontweight='bold')\n",
        "ax1.set_xlabel('x')\n",
        "ax1.set_ylabel('y')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.legend()\n",
        "ax1.axis('equal')\n",
        "\n",
        "# Plot in T0 (transformed space)\n",
        "ax2.scatter([A0[0], B0[0], C0[0]], [A0[1], B0[1], C0[1]],\n",
        "            s=200, c=['red', 'blue', 'green'], alpha=0.7)\n",
        "ax2.plot([A0[0], B0[0]], [A0[1], B0[1]], 'k--', linewidth=2, label='A-B')\n",
        "ax2.plot([B0[0], C0[0]], [B0[1], C0[1]], 'k:', linewidth=2, label='B-C')\n",
        "ax2.plot([A0[0], C0[0]], [A0[1], C0[1]], 'k-.', linewidth=2, label='A-C')\n",
        "ax2.text(A0[0]+0.3, A0[1]+0.3, 'A', fontsize=14, fontweight='bold')\n",
        "ax2.text(B0[0]+0.3, B0[1]+0.3, 'B', fontsize=14, fontweight='bold')\n",
        "ax2.text(C0[0]+0.3, C0[1]+0.3, 'C', fontsize=14, fontweight='bold')\n",
        "ax2.set_title('Transformed Space (T0)\\nA-C are closest', fontsize=12, fontweight='bold')\n",
        "ax2.set_xlabel('x')\n",
        "ax2.set_ylabel('y')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.legend()\n",
        "ax2.axis('equal')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary comparison\n",
        "print(\"=\"*60)\n",
        "print(\"DISTANCE COMPARISON SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nIn T1 Space:\")\n",
        "print(f\"  A-B distance: {dist(A1, B1):.2f}\")\n",
        "print(f\"  B-C distance: {dist(B1, C1):.2f} ← SHORTEST\")\n",
        "print(f\"  A-C distance: {dist(A1, C1):.2f}\")\n",
        "\n",
        "print(\"\\nIn T0 Space (after transformation):\")\n",
        "print(f\"  A-B distance: {dist(A0, B0):.2f}\")\n",
        "print(f\"  B-C distance: {dist(B0, C0):.2f}\")\n",
        "print(f\"  A-C distance: {dist(A0, C0):.2f} ← SHORTEST\")\n",
        "\n",
        "print(\"\\n💡 Key Insight:\")\n",
        "print(\"The SAME points have DIFFERENT nearest neighbors\")\n",
        "print(\"after transformation! This directly affects K-NN predictions.\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "cPYNx0D4_j9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFbpTSBdV29C"
      },
      "source": [
        "## Transformations on MNIST\n",
        "\n",
        "Let us experiment with a subset of the MNIST dataset. We will extract two features from the database for our experiment. We will then transform the data using a transformation matrix and visualize the data in the new coordinate system. We will also see how normalization can help in improving the accuracy of the model. We will reuse previous labs code for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "22ayl0sViF5-"
      },
      "outputs": [],
      "source": [
        "def NN1(traindata, trainlabel, query):\n",
        "    \"\"\"\n",
        "    This function takes in the training data, training labels and a query point\n",
        "    and returns the predicted label for the query point using the nearest neighbour algorithm\n",
        "\n",
        "    traindata: numpy array of shape (n,d) where n is the number of samples and d is the number of features\n",
        "    trainlabel: numpy array of shape (n,) where n is the number of samples\n",
        "    query: numpy array of shape (d,) where d is the number of features\n",
        "\n",
        "    returns: the predicted label for the query point which is the label of the training data which is closest to the query point\n",
        "    \"\"\"\n",
        "    diff = (\n",
        "        traindata - query\n",
        "    )  # find the difference between features. Numpy automatically takes care of the size here\n",
        "    sq = diff * diff  # square the differences\n",
        "    dist = sq.sum(1)  # add up the squares\n",
        "    label = trainlabel[np.argmin(dist)]\n",
        "    return label\n",
        "\n",
        "\n",
        "def NN(traindata, trainlabel, testdata):\n",
        "    \"\"\"\n",
        "    This function takes in the training data, training labels and test data\n",
        "    and returns the predicted labels for the test data using the nearest neighbour algorithm\n",
        "\n",
        "    traindata: numpy array of shape (n,d) where n is the number of samples and d is the number of features\n",
        "    trainlabel: numpy array of shape (n,) where n is the number of samples\n",
        "    testdata: numpy array of shape (m,d) where m is the number of test samples and d is the number of features\n",
        "\n",
        "    returns: the predicted labels for the test data which is the label of the training data which is closest to each test point\n",
        "    \"\"\"\n",
        "    predlabel = np.array([NN1(traindata, trainlabel, i) for i in testdata])\n",
        "    return predlabel\n",
        "\n",
        "\n",
        "def Accuracy(gtlabel, predlabel):\n",
        "    \"\"\"\n",
        "    This function takes in the ground-truth labels and predicted labels\n",
        "    and returns the accuracy of the classifier\n",
        "\n",
        "    gtlabel: numpy array of shape (n,) where n is the number of samples\n",
        "    predlabel: numpy array of shape (n,) where n is the number of samples\n",
        "\n",
        "    returns: the accuracy of the classifier which is the number of correct predictions divided by the total number of predictions\n",
        "    \"\"\"\n",
        "    assert len(gtlabel) == len(\n",
        "        predlabel\n",
        "    ), \"Length of the ground-truth labels and predicted labels should be the same\"\n",
        "    correct = (\n",
        "        gtlabel == predlabel\n",
        "    ).sum()  # count the number of times the groundtruth label is equal to the predicted label.\n",
        "    return correct / len(gtlabel)\n",
        "\n",
        "\n",
        "def cumArray(img):\n",
        "    img2 = img.copy()\n",
        "    for ii in range(1, img2.shape[1]):\n",
        "        # for every row, add up all the rows above it.\n",
        "        img2[ii, :] = img2[ii, :] + img2[ii - 1, :]\n",
        "    img2 = img2 > 0\n",
        "    return img2\n",
        "\n",
        "\n",
        "def getHolePixels(img):\n",
        "    \"\"\"\n",
        "    This function takes in a binary image and returns the pixels that are holes in the image\n",
        "\n",
        "    img: numpy array of shape (n,m) where n is the height of the image and m is the width of the image\n",
        "\n",
        "    returns: a binary image of the same shape as the input image where the holes are filled in\n",
        "    \"\"\"\n",
        "    im1 = cumArray(img)\n",
        "    # rotate and cumulate it again for differnt direction\n",
        "    im2 = np.rot90(cumArray(np.rot90(img)), 3)\n",
        "    im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "    im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "    # this will create a binary image with all the holes filled in.\n",
        "    hull = im1 & im2 & im3 & im4\n",
        "    # remove the original digit to leave behind the holes\n",
        "    hole = hull & ~(img > 0)\n",
        "    return hole\n",
        "\n",
        "\n",
        "def getHullPixels(img):\n",
        "    \"\"\"\n",
        "    This function takes in a binary image and returns the pixels that are the convex hull of the image\n",
        "\n",
        "    img: numpy array of shape (n,m) where n is the height of the image and m is the width of the image\n",
        "\n",
        "    returns: a binary image of the same shape as the input image where the convex hull is filled in\n",
        "    \"\"\"\n",
        "    im1 = cumArray(img)\n",
        "    # rotate and cumulate it again for differnt direction\n",
        "    im2 = np.rot90(cumArray(np.rot90(img)), 3)\n",
        "    im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "    im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "    # this will create a binary image with all the holes filled in.\n",
        "    hull = im1 & im2 & im3 & im4\n",
        "    return hull\n",
        "\n",
        "\n",
        "def minus(a, b):\n",
        "    \"\"\"\n",
        "    This function takes in two binary images and returns the difference between the two images\n",
        "    \"\"\"\n",
        "    return a & ~b\n",
        "\n",
        "\n",
        "def getBoundaryPixels(img):\n",
        "    \"\"\"\n",
        "    This function takes in a binary image and returns the pixels that are the boundary of the image\n",
        "\n",
        "    img: numpy array of shape (n,m) where n is the height of the image and m is the width of the image\n",
        "\n",
        "    returns: a binary image of the same shape as the input image where the boundary is filled in\n",
        "    \"\"\"\n",
        "    img = img.copy() > 0  # binarize the image\n",
        "    rshift = np.roll(img, 1, 1)\n",
        "    lshift = np.roll(img, -1, 1)\n",
        "    ushift = np.roll(img, -1, 0)\n",
        "    dshift = np.roll(img, 1, 0)\n",
        "    boundary = (\n",
        "        minus(img, rshift)\n",
        "        | minus(img, lshift)\n",
        "        | minus(img, ushift)\n",
        "        | minus(img, dshift)\n",
        "    )\n",
        "    return boundary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHz5BVmLUjzb"
      },
      "outputs": [],
      "source": [
        "# loading the dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "train_X = train_X / 255\n",
        "test_X = test_X / 255\n",
        "\n",
        "nclasses = 4\n",
        "\n",
        "# get only for the first 4 classes\n",
        "train_X = train_X[train_y < nclasses]\n",
        "train_y = train_y[train_y < nclasses]\n",
        "test_X = test_X[test_y < nclasses]\n",
        "test_y = test_y[test_y < nclasses]\n",
        "\n",
        "# We are only taking a subset of the training set\n",
        "train_X = train_X[::100].copy()\n",
        "train_y = train_y[::100].copy()  # do the same to the labels\n",
        "\n",
        "# taking a subset of the test set. This code takes every 500th sample\n",
        "test_X = test_X[::100].copy()\n",
        "test_y = test_y[::100].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvavjmfvH515"
      },
      "outputs": [],
      "source": [
        "# feature extraction\n",
        "train_hole = np.array([getHolePixels(i).sum() for i in train_X])\n",
        "test_hole = np.array([getHolePixels(i).sum() for i in test_X])\n",
        "train_bound = np.array([getBoundaryPixels(i).sum() for i in train_X])\n",
        "test_bound = np.array([getBoundaryPixels(i).sum() for i in test_X])\n",
        "# train_hull = np.array([getHullPixels(i).sum() for i in train_X])\n",
        "# test_hull = np.array([getHullPixels(i).sum() for i in test_X])\n",
        "# train_sum = np.sum(train_X, (1, 2)) / (28 * 28)\n",
        "# test_sum = np.sum(test_X, (1, 2)) / (28 * 28)\n",
        "\n",
        "# create the train and test set by combining the appropriate features\n",
        "train_feats = np.vstack(\n",
        "    (train_hole, train_bound)).transpose()\n",
        "test_feats = np.vstack(\n",
        "    (test_hole, test_bound)).transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7qGVrlnQCUy"
      },
      "source": [
        "Let us plot the samples and see what they look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saRzHfi9QAGd"
      },
      "outputs": [],
      "source": [
        "# fix limits of x and y axis so that we can see what is going on\n",
        "xlim = [-100, 300]\n",
        "ylim = [-100, 300]\n",
        "fig, ax = plotData(train_feats, train_y)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCb4DikQP1ck"
      },
      "source": [
        "Check the baseline accuracy on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxVr6bd9PzlI"
      },
      "outputs": [],
      "source": [
        "test_pred = NN(train_feats, train_y, test_feats)\n",
        "acc = Accuracy(test_y, test_pred)\n",
        "print(\"Baseline accuracy:\", acc*100, \"%\", \"for\", nclasses, \"classes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl8Noo8pZRek"
      },
      "source": [
        "Let us try transforming the features and checking their accuracy. The intuition to using the transformation matrix is to find the basis vectors of the dataset and transform the data to a new coordinate system where the basis vectors are orthogonal. This will help in reducing the redundancy in the data and improve the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dUPWRsEZKwo"
      },
      "outputs": [],
      "source": [
        "transform = np.array([[0.5, -0.5], [0, 2.5]])\n",
        "print(transform)\n",
        "\n",
        "train_feats_t = np.matmul(train_feats, transform)\n",
        "# whatever transform we are applying to the training set should be applied to the test set also\n",
        "test_feats_t = np.matmul(test_feats, transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRH4VckHZaWv"
      },
      "outputs": [],
      "source": [
        "fig, ax = plotData(train_feats_t, train_y)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9fknczfZdYF"
      },
      "outputs": [],
      "source": [
        "test_pred = NN(train_feats_t, train_y, test_feats_t)\n",
        "acc = Accuracy(test_y, test_pred)\n",
        "print(\"Baseline accuracy:\", acc*100, \"%\", \"for\", nclasses, \"classes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFBQlAnNZ3on"
      },
      "source": [
        "## Questions:\n",
        "1. Experiment with different transformation matrices and check the accuracy\n",
        "2. Will the same transform used for these two features also work for other features?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXCnbDsVH516"
      },
      "source": [
        "> Exercise: Is it possible that adding all 4 features at a time is not the best strategy? Can you think of a better combination of features that can help in improving the accuracy of the model? Maybe you can try adding 2 features at a time and see if that helps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36TOA47xak20"
      },
      "source": [
        "# Data normalization\n",
        "\n",
        "Sometimes the features of our data have vastly different scales. This will cause the learning algorithm to give more importance to certain features, reducing its performance. Data normalization is a method in which we transform the features so that they have similar scales.\n",
        "\n",
        "Three commonly used feature scaling techniques are rescaling, mean normalization and z-score normalization. Here, we will talk about the simplest one: rescaling.\n",
        "\n",
        "$$\\begin{equation}\n",
        "x' = \\frac {x -min(x)} { max(x) - min(x)}\n",
        "\\end{equation}$$\n",
        "\n",
        "\n",
        "\n",
        "For more information, see [this page](https://towardsdatascience.com/data-normalization-in-machine-learning-395fdec69d02)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni19QKDLZzeo"
      },
      "outputs": [],
      "source": [
        "def rescale(data):\n",
        "    return (data - data.min()) / (data.max() - data.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k83ZMtKeZrQ"
      },
      "source": [
        "We have to apply the rescaling to each feature individually. Also remember to apply the same transform we are using on the train set to the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JLOPwhvehpR"
      },
      "outputs": [],
      "source": [
        "train_feats_rescaled_x = rescale(train_feats[:, 0])\n",
        "train_feats_rescaled_y = rescale(train_feats[:, 1])\n",
        "train_feats_rescaled = np.stack((train_feats_rescaled_x, train_feats_rescaled_y), 1)\n",
        "\n",
        "test_feats_rescaled_x = rescale(test_feats[:, 0])\n",
        "test_feats_rescaled_y = rescale(test_feats[:, 1])\n",
        "test_feats_rescaled = np.stack((test_feats_rescaled_x, test_feats_rescaled_y), 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaZVy9vxfKwX"
      },
      "source": [
        "Let us plot the rescaled features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXyatpwZevOH"
      },
      "outputs": [],
      "source": [
        "fig, ax = plotData(train_feats_rescaled, train_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjBgxE6zglsL"
      },
      "source": [
        "This type of rescaling makes all the features between 0 and 1.\n",
        "\n",
        "Let us calculate the accuracy obtained by this transform:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKQnsj-KgNZc"
      },
      "outputs": [],
      "source": [
        "test_pred = NN(train_feats_rescaled, train_y, test_feats_rescaled)\n",
        "acc = Accuracy(test_y, test_pred)\n",
        "print(\"Accuracy after transform:\", acc*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qYX90Gqg-jO"
      },
      "source": [
        "All 2D linear transformations can be repreented by a transformation matrix. So what is the matrix associated with the rescaling function? Actually, we cannot represent rescaling with a matrix multiplication, because it is not a linear transform. Rescaling involves shifting the origin of the data, which is not allowed under linear transformations.\n",
        "\n",
        "We can represent rescaling as a matrix multiplication followed by a vector addition. Let our first feature vector be called X and second feature vector be called Y. Suppose we want to rescale a data point [a,b]\n",
        "\n",
        "$$ \\begin{equation}\n",
        " \\left\\{  \\begin{aligned}a' \\\\ b' \\end{aligned} \\right\\} =\n",
        " \\left\\{  \\begin{aligned} \\frac{a - min(X)}{max(X) - min(X)} \\\\ \\frac{b - min(Y)}{max(Y) - min(Y)} \\end{aligned} \\right\\} =\n",
        " \\left\\{  \\begin{aligned}&\\frac{1}{max(X)-min(X)} &0\\\\ &0 &\\frac{1}{max(Y)-min(Y)} \\end{aligned}\n",
        " \\right\\}\\left\\{  \\begin{aligned}a \\\\ b \\end{aligned} \\right\\} +\n",
        " \\left\\{  \\begin{aligned} \\frac{ -min(X)}{max(X) - min(X)} \\\\ \\frac{-min(Y)}{max(Y) - min(Y)} \\end{aligned} \\right\\}\n",
        "\\end{equation}$$\n",
        "\n",
        "You can verify this yourself if you wish, though it is not necessary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🎯 Lab Summary: What We Learned\n",
        "\n",
        "**1. Coordinate Transformations Change Everything**\n",
        "- Baseline (no transform): **76.19%** accuracy\n",
        "- With transformation matrix: **80.95%** accuracy  \n",
        "- With rescaling: **80.95%** accuracy\n",
        "- **Improvement: +4.76%** just by choosing better features!\n",
        "\n",
        "**2. Why Transformations Matter for ML**\n",
        "- Transform changes distances between points\n",
        "- K-NN uses distance to find nearest neighbors\n",
        "- Different coordinate system → different neighbors → different predictions\n",
        "\n",
        "---\n",
        "\n",
        "### 📊 Understanding Normalization\n",
        "\n",
        "**The Problem:** Features with different scales dominate distance calculations.\n",
        "\n",
        "**Example:**\n",
        "- Feature 1 (holes): Range 0-250\n",
        "- Feature 2 (boundary): Range 0-100\n",
        "- Distance is dominated by the larger-scale feature!\n",
        "\n",
        "**Solution:** Rescaling brings all features to [0, 1] range.\n",
        "\n",
        "$$x' = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}$$\n",
        "\n",
        "---\n",
        "\n",
        "### 🔍 Types of Normalization\n",
        "\n",
        "| Method | Formula | Range | Use Case |\n",
        "|--------|---------|-------|----------|\n",
        "| **Min-Max (Rescaling)** | $(x - \\min) / (\\max - \\min)$ | [0, 1] | Distance-based algorithms |\n",
        "| **Standardization (Z-score)** | $(x - \\mu) / \\sigma$ | Mean=0, Std=1 | When data has outliers |\n",
        "| **Max Abs Scaling** | $x / \\max(\\|x\\|)$ | [-1, 1] | Sparse data |\n",
        "\n",
        "---\n",
        "\n",
        "### 💡 Practical Tips for Your Projects\n",
        "\n",
        "**When to Use Transformations:**\n",
        "- ✓ Features have very different scales (e.g., age vs salary)\n",
        "- ✓ Using distance-based algorithms (K-NN, K-Means)\n",
        "- ✓ Want to reduce feature correlation\n",
        "- ✓ Need better class separation\n",
        "\n",
        "**Best Practices:**\n",
        "1. **Always fit on training data only:** Compute min/max from training set\n",
        "2. **Apply same transform to test data:** Use training min/max on test set\n",
        "3. **Normalize each feature separately:** Different features need different scaling\n",
        "4. **Visualize before and after:** Check if classes are better separated\n",
        "\n",
        "---\n",
        "\n",
        "### 🧮 Quick Reference: Matrix Operations\n",
        "\n",
        "```python\n",
        "# Transform multiple points at once\n",
        "transformed_data = np.matmul(original_data, Transform_Matrix.T)\n",
        "\n",
        "# Or equivalently\n",
        "transformed_data = original_data @ Transform_Matrix.T\n",
        "\n",
        "# Rescale a feature\n",
        "normalized = (feature - feature.min()) / (feature.max() - feature.min())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 🤔 Think About This\n",
        "\n",
        "**Q:** Why can't we represent rescaling as a matrix multiplication?\n",
        "\n",
        "**A:** Rescaling shifts the origin: $x' = (x - \\min) / (\\max - \\min)$.\n",
        "The subtraction of $\\min$ is a translation, not a linear transformation.\n",
        "Linear transformations must preserve the origin (0 → 0).\n",
        "\n",
        "However, **standardization** can be partially represented:\n",
        "- Centering: $x - \\mu$ (affine, not linear)\n",
        "- Scaling: $x / \\sigma$ (linear!)\n",
        "\n",
        "---\n",
        "\n",
        "### 📝 Exercise Ideas\n",
        "\n",
        "1. **Experiment with transforms:** Try [[2, 0], [0, 0.5]] - what happens to accuracy?\n",
        "2. **Mix normalization + transformation:** First rescale, then transform\n",
        "3. **Try other features:** Use hull pixels + sum instead of holes + boundary\n",
        "4. **Z-score normalization:** Implement $(x - \\mu) / \\sigma$ and compare results\n",
        "5. **Visualize feature distributions:** Plot histograms before/after normalization"
      ],
      "metadata": {
        "id": "TEt0ujT0_s1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1. Experiment with transforms: Try [[2, 0], [0, 0.5]] – what happens to accuracy?\n",
        "\n",
        "This matrix stretches the x-axis (by factor 2) and compresses the y-axis (by factor 0.5).\n",
        "So each digit becomes wide and short.\n",
        "\n",
        "Expected effect on accuracy:\n",
        "\n",
        "If your classifier relies on shape-based features (like pixel coordinates, boundary, hull, etc.), accuracy will drop, because the transformed digit looks different from original training examples.\n",
        "\n",
        "If you trained on untransformed data but test with transformed data → accuracy ↓\n",
        "\n",
        "If you train and test with the same transform → accuracy may stay similar\n",
        "\n",
        "✅ This experiment tests scale sensitivity of your feature extraction.\n",
        "\n",
        "2. Mix normalization + transformation: First rescale, then transform\n",
        "\n",
        "Flow:\n",
        "Raw Image → Normalization (pixel scaling 0-1 or Z-score) → Geometric Transform (stretch, rotate, etc.) → Feature Extraction\n",
        "\n",
        "Why do this?\n",
        "\n",
        "Normalization removes pixel-intensity bias\n",
        "\n",
        "Transformation tests geometric robustness\n",
        "\n",
        "📌 If you transform before normalization, the scale of pixel values may distort statistics.\n",
        "📌 Doing normalization first keeps the pixel distribution stable even after transform.\n",
        "\n",
        "3. Try other features: Use hull_pixels + sum instead of holes + boundary\n",
        "\n",
        "Current feature set:\n",
        "\n",
        "num_holes (number of enclosed regions)\n",
        "\n",
        "boundary_pixels\n",
        "\n",
        "New experiment feature set:\n",
        "\n",
        "hull_pixels → Pixels in convex hull (shape size/area)\n",
        "\n",
        "sum → Total pixel intensity (darker digits have higher values)\n",
        "\n",
        "Why this matters:\n",
        "\n",
        "holes + boundary is topology-based\n",
        "\n",
        "hull_pixels + sum is area/ink-based\n",
        "\n",
        "✅ You can measure which feature pair gives better class separation\n",
        "✅ Try classification again and compare accuracy\n",
        "\n",
        "4. Z-score normalization: Implement (x − μ)/σ and compare results\n",
        "\n",
        "Formula:\n",
        "\n",
        "𝑧\n",
        "=\n",
        "𝑥\n",
        "−\n",
        "𝜇\n",
        "𝜎\n",
        "z=\n",
        "σ\n",
        "x−μ\n",
        "\t​\n",
        "\n",
        "\n",
        "Where\n",
        "\n",
        "𝑥\n",
        "x = feature value\n",
        "\n",
        "𝜇\n",
        "μ = mean of feature\n",
        "\n",
        "𝜎\n",
        "σ = standard deviation\n",
        "\n",
        "✅ Normalizes all features to mean = 0, std = 1\n",
        "✅ Fixes \"feature dominance\" (e.g., boundary values may be 0-200, holes only 0-3)\n",
        "\n",
        "Expected observation:\n",
        "\n",
        "Classifier performance improves, especially for distance-based models (kNN, SVM, logistic regression)\n",
        "\n",
        "Feature distributions become centered and comparable\n",
        "\n",
        "5. Visualize feature distributions: Plot histograms before/after normalization\n",
        "\n",
        "You should draw:\n",
        "\n",
        "Feature\tBefore Normalization\tAfter Z-Score\n",
        "boundary_pixels\twide spread, skewed\tcentered at 0\n",
        "holes\tsmall range (0-2), narrow\tspread but normalized\n",
        "hull_pixels\tlarge numeric range\tshrunk to unit scale\n",
        "\n",
        "✅ Use matplotlib.pyplot.hist()\n",
        "✅ Plot side-by-side to show effect of normalization\n",
        "\n",
        "Example pseudocode:\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(feature_before, bins=20)\n",
        "plt.title(\"Before Normalization\")\n",
        "plt.show()\n",
        "\n",
        "plt.hist(feature_after, bins=20)\n",
        "plt.title(\"After Z-score Normalization\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v7lBiVBKfo-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qpWCA6vc_tZM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}