{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WliM6KDVWsIR"
      },
      "source": [
        "# Module 5 Project: Regression analysis on a COVID-dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "f1dc0b53",
        "outputId": "eee56be6-4f13-4da0-a8de-2f7755cca7df"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_file.csv' with the actual path to your CSV file\n",
        "# For example, if your file is in the same directory, just use its name.\n",
        "# If it's online, you can use the URL.\n",
        "csv_file_path = 'your_file.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Display the first 5 rows of the DataFrame to verify it loaded correctly\n",
        "display(df.head())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'your_file.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-72811319.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# If it's online, you can use the URL.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcsv_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'your_file.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Display the first 5 rows of the DataFrame to verify it loaded correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_file.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96ab351a"
      },
      "source": [
        "### Explanation:\n",
        "\n",
        "1.  **`import pandas as pd`**: This line imports the pandas library and assigns it the alias `pd`, which is a common convention.\n",
        "2.  **`csv_file_path = 'your_file.csv'`**: This defines the path to your CSV file. You'll need to replace `'your_file.csv'` with the actual location of your file. This could be a local path (e.g., `'data/my_data.csv'`) or a URL (e.g., `'https://example.com/data.csv'`).\n",
        "3.  **`df = pd.read_csv(csv_file_path)`**: This is the core function call. `pd.read_csv()` reads the data from the specified CSV file and creates a DataFrame object, which is then stored in the variable `df`.\n",
        "4.  **`display(df.head())`**: This line displays the first five rows of the newly created DataFrame. This is a good practice to quickly check if the data was loaded as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sOSbkXOWsIW"
      },
      "source": [
        "In this project, we will use the concepts of regression and regularization we have learnt to predict early Covid-19 cases. We shall use linear regression, polynomial regression and ridge regression to obtain a reasonably good estimate of the future cases. Try experimenting with hyperparameters to obtain better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Tbh4Yy6WsIW"
      },
      "source": [
        "## Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7l6rE-TWsIW"
      },
      "source": [
        "### 1. **Load the data** into a pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLnDD-vyWsIX"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy  as np\n",
        "import scipy.integrate\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from matplotlib.pylab import rcParams\n",
        "rcParams['figure.figsize'] = 10, 8\n",
        "\n",
        "import copy\n",
        "from   sklearn.metrics       import mean_squared_error, mean_absolute_error\n",
        "from   sklearn.linear_model  import LinearRegression, BayesianRidge\n",
        "from   sklearn.tree          import DecisionTreeRegressor\n",
        "from   sklearn.preprocessing import PolynomialFeatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLMSF3wuWsIY"
      },
      "outputs": [],
      "source": [
        "path = \"https://raw.githubusercontent.com/PranavTadimeti/Regression_Project/main/covid_19_data.csv\"\n",
        "df_orig = pd.read_csv(path)\n",
        "print(df_orig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DLCS3sqWsIa"
      },
      "source": [
        "### 2. Create a new dataframe which counts the cumulative total number of cases, the cumulative total number of deaths, and also  cumulative total number of recoveries for each date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZixfTp3tWsIa"
      },
      "outputs": [],
      "source": [
        "df = copy.deepcopy(df_orig)\n",
        "df.drop('Last Update',inplace=True,axis=1)\n",
        "date_lst  = df.ObservationDate.unique()\n",
        "date_dict = {}\n",
        "\n",
        "for i in range(len(date_lst)):\n",
        "    df_temp = df.loc[df['ObservationDate'] == date_lst[i]]\n",
        "    date_dict[date_lst[i]] = df_temp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzPpZMmxWsIb"
      },
      "outputs": [],
      "source": [
        "date_tot_tup_dict = {};\n",
        "for date, df in date_dict.items():\n",
        "    tup_temp = (df['Confirmed'].sum(), df['Deaths'].sum(), df['Recovered'].sum())\n",
        "    date_tot_tup_dict[date] = tup_temp\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(date_tot_tup_dict)"
      ],
      "metadata": {
        "id": "8lXxIhFeL9CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acpnS2-lWsIc"
      },
      "outputs": [],
      "source": [
        "df_date_tots = pd.DataFrame(date_tot_tup_dict)\n",
        "df_date_tots = df_date_tots.transpose()\n",
        "df_date_tots.columns = ['Confirmed', 'Deaths', 'Recovered']\n",
        "print(df_date_tots.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDXwg90qWsId"
      },
      "source": [
        "### 3. Create a new column in the dataframe called **“closed cases”**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5rCWLJkWsId"
      },
      "outputs": [],
      "source": [
        "df_date_tots['Closed Cases'] = df_date_tots['Deaths'] + df_date_tots['Recovered']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVLYaGHJWsIe"
      },
      "source": [
        "### 4. Create a new column in the dataframe called “active cases”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqtKS_pwWsIe"
      },
      "outputs": [],
      "source": [
        "df_date_tots['Active Cases'] = df_date_tots['Confirmed'] - df_date_tots['Closed Cases']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wqbh5VreWsIc"
      },
      "source": [
        "### 5. **Plot** the total number of cases per day over time and summarize findings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoFQ2r9HWsIc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = [15,5])\n",
        "plt.plot(df_date_tots['Confirmed'], label = \"Confirmed Cases\")\n",
        "plt.plot(df_date_tots['Deaths'], label    = \"Deaths\")\n",
        "plt.plot(df_date_tots['Recovered'], label = \"Recovered Cases\")\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"Day\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation = 90);\n",
        "start_date = str(date_lst[0]);\n",
        "fin_date   = str(date_lst[len(date_lst) -1])\n",
        "plt.title(\"Total Cases, Deaths, and Recoveries : \" + start_date + \" - \" + fin_date);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy0VdsvfWsId"
      },
      "source": [
        "All of the three curves seem to be exponential (start of logistic curve). The confirmed cases was obviously higher than the deaths and recovered cases. The rate of the the recovered cases seems to be higher than that of the death curve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftsCGpUzWsIe"
      },
      "source": [
        "### 6. Create one **plot** showing the trend of number of active cases and closed cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOp3Ylq0WsIe"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = [15,5])\n",
        "plt.plot(df_date_tots['Active Cases'], label = \"Active Cases\")\n",
        "plt.plot(df_date_tots['Closed Cases'], label = \"Closed Cases\")\n",
        "\n",
        "plt.legend();\n",
        "plt.xlabel(\"Day\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation = 90)\n",
        "start_date = str(date_lst[0])\n",
        "fin_date   = str(date_lst[len(date_lst) -1])\n",
        "plt.title(\"Active Cases vs Closed Cases COVID-19 : \" + start_date + \" - \" + fin_date);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYWfScVuWsIf"
      },
      "source": [
        "The number of active cases is higher than the number of closed cases as of yet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsoLvyhhWsIf"
      },
      "source": [
        "### 7. Growth Factor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Growth factor** is the factor by which a quantity multiplies itself over time. In the below cell, we calculate the GF of the confirmed, recovered and death cases.\n"
      ],
      "metadata": {
        "id": "tLb4At8ONMnZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fClW0mUsWsIf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "81daaebf-e5d9-4edd-9572-db85befbb533"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'date_lst' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3700421734.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrowth_len_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_lst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconfirmed_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_date_tots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Confirmed\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdeath_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_date_tots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Deaths\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrecovered_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_date_tots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Recovered\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfGF_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'date_lst' is not defined"
          ]
        }
      ],
      "source": [
        "growth_len_lst = len(date_lst) - 1\n",
        "confirmed_lst = df_date_tots[\"Confirmed\"]\n",
        "death_lst = df_date_tots[\"Deaths\"]\n",
        "recovered_lst = df_date_tots[\"Recovered\"]\n",
        "confGF_lst = []\n",
        "deathsGF_lst = []\n",
        "recovGF_lst = []\n",
        "for i in range(growth_len_lst):\n",
        "    confirmedGF = confirmed_lst[i+1] / confirmed_lst[i]\n",
        "    confGF_lst.append(confirmedGF)\n",
        "    deathGF = death_lst[i+1] / death_lst[i]\n",
        "    deathsGF_lst.append(deathGF)\n",
        "    recoveredGF = recovered_lst[i+1] / recovered_lst[i]\n",
        "    recovGF_lst.append(recoveredGF);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Create one plot showing the Growth factor of confirmed, recovered and death cases wrt days"
      ],
      "metadata": {
        "id": "DGHVC9eVN2in"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVvAED3CWsIf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = [15,5])\n",
        "plt.plot(confGF_lst, label = \"Growth Factor of Confirmed Cases\")\n",
        "plt.plot(deathsGF_lst, label = \"Growth Factor of Deaths\")\n",
        "plt.plot(recovGF_lst, label = \"Growth Factor of Recovered Cases\")\n",
        "x = []\n",
        "for i in range((growth_len_lst)):\n",
        "    x.append(1)\n",
        "plt.plot(x, label = \"Growth Factor = 1.0\")\n",
        "\n",
        "#plt.grid()\n",
        "plt.legend()\n",
        "plt.xlabel(\"Day\")\n",
        "plt.ylabel(\"Growth Ratio\")\n",
        "plt.ylim(.5,2)\n",
        "plt.xticks(rotation = 90)\n",
        "start_date = str(date_lst[0])\n",
        "fin_date   = str(date_lst[len(date_lst) -1])\n",
        "plt.title(\"Growth Factors of Confirmed, Death, and Recovered Cases COVID-19 : \" +start_date +\" - \" +fin_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaB_7h4eWsIf"
      },
      "source": [
        "# **Part 2 - Prediction Using Linear Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7cIKMQBWsIg"
      },
      "source": [
        "#### To make our data to be compatible with *sklearn* format, create a new column called “Days since” which tracks the number of days since the initial date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTU1FrjtWsIg"
      },
      "outputs": [],
      "source": [
        "days_since_lst = []\n",
        "for i in range(len(date_lst)):\n",
        "    days_since_lst.append(i)\n",
        "df_date_tots[\"Days Since:\"] = days_since_lst\n",
        "df_date_tots = df_date_tots[[\"Days Since:\", \"Confirmed\", \"Deaths\", \"Recovered\", \"Active Cases\", \"Closed Cases\"]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOSUms52WsIg"
      },
      "source": [
        "### 8. Take the earliest 85% of the dates as **train** and the rest as **test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knA90j_DWsIg"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = np.array(df_date_tots[\"Days Since:\"]).reshape(-1,1)\n",
        "y = np.array(df_date_tots[\"Confirmed\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxqmPlfdWsIg"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    test_size = 0.15,\n",
        "                                                    shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w2OC1hFWsIg"
      },
      "source": [
        "### 9. We can try different regression and regularizations we have seen before"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruIA7fzNWsIg"
      },
      "source": [
        "#### 9.1 Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7olNxZLWsIg"
      },
      "outputs": [],
      "source": [
        "lin_model = LinearRegression(fit_intercept = False)\n",
        "lin_model.fit(X_train, y_train)\n",
        "test_lin_pred = lin_model.predict(X_test)\n",
        "lin_pred = lin_model.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjnoSh0EWsIg"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = [15,5])\n",
        "# plotting the actual values for the future days\n",
        "plt.plot(X_test,\n",
        "         y_test,\n",
        "         label = \"Actual Confirmed Cases\")\n",
        "# plotting the predicited values for the future days\n",
        "plt.plot(X_test,\n",
        "         test_lin_pred,\n",
        "         label = \"Lin Regression predicted Confirmed Cases\")\n",
        "plt.grid();\n",
        "plt.legend();\n",
        "plt.xlabel(\"Day\", size = 25)\n",
        "plt.ylabel(\"Count\", size = 25)\n",
        "plt.xticks(rotation = 90, size = 15)\n",
        "plt.show()\n",
        "\n",
        "print('MAE:', mean_absolute_error (test_lin_pred, X_test))\n",
        "print('MSE:', mean_squared_error  (test_lin_pred, X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QNzShYEWsIh"
      },
      "source": [
        "#### Polynomial Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zo63r_bfWsIh"
      },
      "outputs": [],
      "source": [
        "poly = PolynomialFeatures(degree=5)\n",
        "poly_X_train = poly.fit_transform(X_train)\n",
        "poly_X_test  = poly.fit_transform(X_test)\n",
        "poly_X = poly.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD_FE4jzWsIh"
      },
      "outputs": [],
      "source": [
        "linear_model = LinearRegression(fit_intercept=False)\n",
        "linear_model.fit(poly_X_train, y_train)\n",
        "test_poly_pred = linear_model.predict(poly_X_test)\n",
        "poly_pred = linear_model.predict(poly_X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4us2pO6fWsIh"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = [15,5])\n",
        "\n",
        "# plotting the actual values for the future days\n",
        "plt.plot(X_test,\n",
        "         y_test,\n",
        "         label = \"Actual Confirmed Cases\")\n",
        "\n",
        "# plotting the predicited values for the future days\n",
        "plt.plot(X_test,\n",
        "         test_poly_pred,\n",
        "         label = \"Polynomial Regression Confirmed Cases\")\n",
        "plt.grid();\n",
        "plt.legend();\n",
        "plt.xlabel(\"Day\", size = 25)\n",
        "plt.ylabel(\"Count\", size = 25)\n",
        "plt.xticks(rotation = 90, size = 15);\n",
        "plt.show()\n",
        "\n",
        "print('MAE:', mean_absolute_error(test_poly_pred, y_test))\n",
        "print('MSE:',mean_squared_error(test_poly_pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37HI0h5aWsIh"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(X,\n",
        "         y,\n",
        "         label = 'Actual Future Cases')\n",
        "\n",
        "plt.plot(X,\n",
        "         poly_pred,\n",
        "         label = 'Polynomial Regression Prediction of Future Cases',\n",
        "         linestyle = \"dashed\")\n",
        "\n",
        "plt.plot(X_train,\n",
        "         y_train,\n",
        "         label = 'Training Cases')\n",
        "\n",
        "plt.xlabel('Days Since', size = 30)\n",
        "plt.ylabel('# of Cases', size = 30)\n",
        "plt.legend()\n",
        "plt.xticks(size=20)\n",
        "plt.yticks(size=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N88Q07dOWsIh"
      },
      "source": [
        "### 9.2 Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "teIVVvx2WsIi",
        "outputId": "7c958aa9-4b0c-4db8-bc1a-4349d3515c23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'BayesianRidge' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3512276056.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                  'lambda_2' : lambda_2 }\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mbayesian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m bayesian_search = RandomizedSearchCV(bayesian,\n\u001b[1;32m     15\u001b[0m                                      \u001b[0mbayesian_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'BayesianRidge' is not defined"
          ]
        }
      ],
      "source": [
        "tol      = [1e-4, 1e-3, 1e-2]\n",
        "alpha_1  = [1e-7, 1e-6, 1e-5, 1e-4]\n",
        "alpha_2  = [1e-7, 1e-6, 1e-5, 1e-4]\n",
        "lambda_1 = [1e-7, 1e-6, 1e-5, 1e-4]\n",
        "lambda_2 = [1e-7, 1e-6, 1e-5, 1e-4]\n",
        "\n",
        "bayesian_grid = {'tol': tol,\n",
        "                 'alpha_1': alpha_1,\n",
        "                 'alpha_2' : alpha_2,\n",
        "                 'lambda_1': lambda_1,\n",
        "                 'lambda_2' : lambda_2 }\n",
        "\n",
        "bayesian = BayesianRidge(fit_intercept=False)\n",
        "bayesian_search = RandomizedSearchCV(bayesian,\n",
        "                                     bayesian_grid,\n",
        "                                     scoring='neg_mean_squared_error',\n",
        "                                     cv=3,\n",
        "                                     return_train_score=True,\n",
        "                                     n_jobs=-1,\n",
        "                                     n_iter=40,\n",
        "                                     verbose=1)\n",
        "\n",
        "bayesian_search.fit(X_train, y_train)\n",
        "\n",
        "print(bayesian_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xHAtU8uoWsIi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "d21c9230-d386-4667-b072-c657ecc1f663"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'bayesian_search' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-449111560.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test_ridge_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayesian_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_ridge_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbayesian_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bayesian_search' is not defined"
          ]
        }
      ],
      "source": [
        "y_test_ridge_pred = bayesian_search.predict(X_test);\n",
        "y_ridge_pred = bayesian_search.predict(X);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DorAwFflWsIi"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = [15,5])\n",
        "\n",
        "# plotting the actual values for the future days\n",
        "plt.plot(X_test,\n",
        "         y_test,\n",
        "         label = \"Actual Confirmed Cases\")\n",
        "\n",
        "# plotting the predicited values for the future days\n",
        "plt.plot(X_test,\n",
        "         y_test_ridge_pred,\n",
        "         label = \"Ridge predicted Confirmed Cases\")\n",
        "plt.grid();\n",
        "plt.legend();\n",
        "plt.xlabel(\"Day\", size = 25)\n",
        "plt.ylabel(\"Count\", size = 25)\n",
        "plt.xticks(rotation = 90, size = 15);\n",
        "plt.show()\n",
        "\n",
        "print('MAE:', mean_absolute_error (y_test_ridge_pred, X_test))\n",
        "print('MSE:', mean_squared_error  (y_test_ridge_pred, X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ecv5T1tWsIi"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(X,\n",
        "         y,\n",
        "         label = 'Actual Future Cases')\n",
        "plt.plot(X,\n",
        "         y_ridge_pred,\n",
        "         label = 'Ridge Prediction of Future Cases',\n",
        "         linestyle = \"dashed\")\n",
        "plt.plot(X_train,\n",
        "         y_train,\n",
        "         label = 'Training Cases')\n",
        "\n",
        "#plt.title('# of Coronavirus Cases Over Time', size=30)\n",
        "plt.xlabel('Days Since', size = 30)\n",
        "plt.ylabel('# of Cases', size = 30)\n",
        "plt.legend()\n",
        "plt.xticks(size=20)\n",
        "plt.yticks(size=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-B8ug8NWsIi"
      },
      "source": [
        "#### Polynomial Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Qy2U6_bWsIi"
      },
      "outputs": [],
      "source": [
        "bayesian_search_poly = RandomizedSearchCV(bayesian,\n",
        "                                     bayesian_grid,\n",
        "                                     scoring='neg_mean_squared_error',\n",
        "                                     cv=3,\n",
        "                                     return_train_score=True,\n",
        "                                     n_jobs=-1,\n",
        "                                     n_iter=40,\n",
        "                                     verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihb19TUsWsIj"
      },
      "outputs": [],
      "source": [
        "bayesian_search_poly.fit(poly_X_train, y_train);\n",
        "print(bayesian_search_poly.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-_3BtX3WsIj"
      },
      "outputs": [],
      "source": [
        "bayesian_poly_confirmed = bayesian_search_poly.best_estimator_\n",
        "test_poly_bayesian_pred = bayesian_poly_confirmed.predict(poly_X_test)\n",
        "bayesian_poly_pred = bayesian_poly_confirmed.predict(poly_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4DSJoY4WsIj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = [15,5])\n",
        "\n",
        "# plotting the actual values for the future days\n",
        "plt.plot(X_test,\n",
        "         y_test,\n",
        "         label = \"Actual Confirmed Cases\")\n",
        "\n",
        "# plotting the predicited values for the future days\n",
        "plt.plot(X_test,\n",
        "         test_poly_bayesian_pred,\n",
        "         label = \"Ridge Polynomial predicted Confirmed Cases\")\n",
        "plt.grid();\n",
        "plt.legend();\n",
        "plt.xlabel(\"Day\", size = 25)\n",
        "plt.ylabel(\"Count\", size = 25)\n",
        "plt.xticks(rotation = 90, size = 15)\n",
        "plt.show()\n",
        "\n",
        "print ('MAE:', mean_absolute_error(test_poly_bayesian_pred, y_test))\n",
        "print ('MSE:', mean_squared_error (test_poly_bayesian_pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x_5sBI_WsIj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(X,\n",
        "         y,\n",
        "         label = 'Actual Future Cases')\n",
        "plt.plot(X,\n",
        "         bayesian_poly_pred,\n",
        "         label = 'Ridge Polynomial Prediction of Future Cases',\n",
        "         linestyle = \"dashed\")\n",
        "plt.plot(X_train,\n",
        "         y_train,\n",
        "         label = 'Training Cases')\n",
        "\n",
        "#plt.title('# of Coronavirus Cases Over Time', size=30)\n",
        "plt.xlabel('Days Since', size = 30)\n",
        "plt.ylabel('# of Cases', size = 30)\n",
        "#plt.grid()\n",
        "plt.legend()\n",
        "plt.xticks(size=20)\n",
        "plt.yticks(size=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQozj8naWsIj"
      },
      "outputs": [],
      "source": [
        "print(\"Polynomial Regression \")\n",
        "print('\\tMAE:', mean_absolute_error(test_poly_pred, y_test))\n",
        "print('\\tMSE:',mean_squared_error(test_poly_pred, y_test))\n",
        "\n",
        "print(\"\\nRidge Polynomial Regression \")\n",
        "print ('\\tMAE:', mean_absolute_error(test_poly_bayesian_pred, y_test))\n",
        "print ('\\tMSE:', mean_squared_error (test_poly_bayesian_pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MwCesFWsIj"
      },
      "source": [
        "From Mean Absolute Error and Mean Squared Error values, Ridge Polynomial Regression Model seems to be the best model."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}